{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49afef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from src.extract_logs import stream_lines\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import config.config as conf\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "from collections import Counter,defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae650cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lines_per_label_train = conf.MAX_LINES_PER_LABEL_TRAIN\n",
    "max_lines_per_label_test = conf.MAX_LINES_PER_LABEL_TEST\n",
    "\n",
    "max_lines_per_app_train = conf.MAX_LINES_PER_APP_TRAIN\n",
    "max_lines_per_app_test = conf.MAX_LINES_PER_APP_TEST\n",
    "\n",
    "max_info_ratio = conf.MAX_INFO_RATIO\n",
    "\n",
    "error_pattern = re.compile(conf.ERROR_PATTERN,re.I)\n",
    "warn_pattern = re.compile(conf.WARN_PATTERN,re.I)\n",
    "\n",
    "processed_data_path = Path(conf.PROCESSED_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c5abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_app_split(app_to_label, train_size=0.7, val_size=0.15, test_size=0.15, seed=42):\n",
    "    apps = np.array(sorted(app_to_label.keys()))\n",
    "    y = np.array([app_to_label[a] for a in apps])\n",
    "\n",
    "    sss1 = StratifiedShuffleSplit(n_splits=1, train_size=train_size, random_state=seed)\n",
    "    train_idx, vt_idx = next(sss1.split(apps, y))\n",
    "\n",
    "    apps_train = apps[train_idx]\n",
    "    y_vt = y[vt_idx]\n",
    "\n",
    "    vt_apps = apps[vt_idx]\n",
    "    test_ratio_in_vt = test_size / (val_size + test_size)\n",
    "    sss2 = StratifiedShuffleSplit(n_splits=1, test_size=test_ratio_in_vt, random_state=seed+1)\n",
    "    val_idx_rel, test_idx_rel = next(sss2.split(vt_apps, y_vt))\n",
    "\n",
    "    apps_val  = vt_apps[val_idx_rel]\n",
    "    apps_test = vt_apps[test_idx_rel]\n",
    "    return set(apps_train), set(apps_val), set(apps_test)\n",
    "\n",
    "\n",
    "def line_priority(line:str)->float:\n",
    "    if error_pattern.search(line):\n",
    "        return 3.0\n",
    "    if(error_pattern).search(line):\n",
    "        return 1.5\n",
    "    return 1.0\n",
    "\n",
    "def collect_lines_for_split(apps_subset, app_to_label, per_label_cap=max_lines_per_label_train, per_app_cap=max_lines_per_app_train, max_info_ratio=max_info_ratio):\n",
    "    per_label_counts = Counter()\n",
    "    texts,labels = [],[]\n",
    "    app_to_indices = defaultdict(list)\n",
    "\n",
    "    apps_list = list(apps_subset)\n",
    "    random.shuffle(apps_list)\n",
    "\n",
    "    inv_df = pd.read_csv(processed_data_path/\"inventory.csv\")\n",
    "\n",
    "\n",
    "    for app in apps_list:\n",
    "        label = app_to_label[app]\n",
    "        \n",
    "        log_files_paths = list(inv_df[inv_df[\"application\"]==app][\"file_path\"])\n",
    "\n",
    "        scored = []\n",
    "\n",
    "        for lf_path in log_files_paths:\n",
    "            lines = stream_lines(Path(lf_path))\n",
    "            for line in lines:\n",
    "                scored.append((line_priority(line),line))\n",
    "\n",
    "        if not scored:continue\n",
    "\n",
    "        scored.sort(key=lambda x:x[0],reverse=True)\n",
    "\n",
    "        chosen, info_count = [],0\n",
    "        info_limit = int(max_info_ratio*per_app_cap) if per_app_cap>0 else 0\n",
    "        for score,line in scored:\n",
    "            if(len(chosen)>per_app_cap):\n",
    "                break\n",
    "            is_info = (score==1.0)\n",
    "            if is_info and info_count>=info_limit:\n",
    "                continue\n",
    "            chosen.append(line)\n",
    "            if is_info:\n",
    "                info_count+=1\n",
    "\n",
    "        for line in chosen:\n",
    "            if(per_label_counts[app]> per_label_cap):\n",
    "                break\n",
    "            idx = len(texts)\n",
    "            texts.append(line)\n",
    "            labels.append(label)\n",
    "            app_to_indices[app].append(idx)\n",
    "            per_label_counts[app]+=1\n",
    "\n",
    "    return texts,labels,app_to_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30db45a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_stats_df = pd.read_csv(processed_data_path/\"app_status.csv\",index_col=\"application\")\n",
    "app_to_label = dict()\n",
    "for row in app_stats_df.iterrows():\n",
    "    app = row[0]\n",
    "    app_to_label[app] = app_stats_df.loc[app,\"label\"]\n",
    "\n",
    "labels_set = sorted(set(app_to_label.values()))\n",
    "\n",
    "apps = np.array(sorted(app_to_label.keys()))\n",
    "y= np.array([app_to_label[a] for a in apps])\n",
    "\n",
    "apps_train, apps_val, apps_test = stratified_app_split(app_to_label)\n",
    "\n",
    "X_train_lines, y_train_labels, appidx_train = collect_lines_for_split(apps_train, app_to_label)\n",
    "X_val_lines, y_val_labels, appidx_val = collect_lines_for_split(apps_val, app_to_label)\n",
    "X_test_lines, y_test_labels, appidx_test = collect_lines_for_split(apps_test, app_to_label)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(list(labels_set)) \n",
    "y_train = le.transform(y_train_labels)\n",
    "y_val   = le.transform(y_val_labels)\n",
    "y_test  = le.transform(y_test_labels)\n",
    "\n",
    "num_classes = len(le.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bb80c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers,optimizers,callbacks,regularizers\n",
    "from sklearn.metrics import classification_report,confusion_matrix,f1_score,accuracy_score\n",
    "# from tensorflow.keras import layers,optimizers,callbacks,regularizers\n",
    "\n",
    "SEQ_LEN = conf.SEQ_LEN     \n",
    "VOCAB = conf.VOCAB       \n",
    "EMBED_DIM = conf.EMBED_DIM\n",
    "DROPOUT = conf.DROPOUT\n",
    "BATCH_SIZE = conf.BATCH_SIZE\n",
    "EPOCHS = conf.EPOCHS\n",
    "BASE_LR = conf.BASE_LR     \n",
    "CONF_FLOOR = conf.BASE_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19015e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 90\n"
     ]
    }
   ],
   "source": [
    "vec = layers.TextVectorization(\n",
    "    standardize=None,\n",
    "    split=\"character\",\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=SEQ_LEN,\n",
    "    vocabulary=VOCAB\n",
    ")\n",
    "vec.adapt(tf.data.Dataset.from_tensor_slices(np.array(X_train_lines, dtype=object)).batch(2048))\n",
    "vocab = vec.get_vocabulary()\n",
    "with open(Path(conf.PROCESSED_DATA_PATH) / \"char_vocab.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for tok in vocab:\n",
    "        f.write(tok + \"\\n\")\n",
    "print(\"Vocab size:\", len(vocab))\n",
    "\n",
    "\n",
    "def make_ds(texts, labels, batch_size, shuffle=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((np.array(texts, dtype=object), np.array(labels, dtype=np.int64)))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=min(len(texts), 100000), seed=42, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "def vectorize_batch(text, label):\n",
    "    return vec(text), label\n",
    "\n",
    "train_ds = make_ds(X_train_lines, y_train, BATCH_SIZE, shuffle=True).map(vectorize_batch, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds   = make_ds(X_val_lines,   y_val,   BATCH_SIZE, shuffle=False).map(vectorize_batch, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds  = make_ds(X_test_lines,  y_test,  BATCH_SIZE, shuffle=False).map(vectorize_batch, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d7553e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\My_Programs\\Hadoop log anamoly detection\\venv\\Lib\\site-packages\\keras\\src\\layers\\layer.py:982: UserWarning: Layer 'conv1d' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "d:\\My_Programs\\Hadoop log anamoly detection\\venv\\Lib\\site-packages\\keras\\src\\layers\\layer.py:982: UserWarning: Layer 'conv1d_1' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "d:\\My_Programs\\Hadoop log anamoly detection\\venv\\Lib\\site-packages\\keras\\src\\layers\\layer.py:982: UserWarning: Layer 'conv1d_2' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,760</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,528</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">30,816</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">43,104</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout1d   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">236,160</span> │ spatial_dropout1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,608</span> │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m5,760\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │     \u001b[38;5;34m18,528\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │     \u001b[38;5;34m30,816\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m96\u001b[0m)   │     \u001b[38;5;34m43,104\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m288\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m288\u001b[0m)  │      \u001b[38;5;34m1,152\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m288\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout1d   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m288\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m160\u001b[0m)  │    \u001b[38;5;34m236,160\u001b[0m │ spatial_dropout1… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m20,608\u001b[0m │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m516\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">356,644</span> (1.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m356,644\u001b[0m (1.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">356,068</span> (1.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m356,068\u001b[0m (1.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> (2.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m576\u001b[0m (2.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_model(vocab_size, num_classes):\n",
    "    inputs = layers.Input(shape=(SEQ_LEN,), dtype=tf.int64)\n",
    "    x = layers.Embedding(vocab_size, EMBED_DIM, mask_zero=True,\n",
    "                         embeddings_regularizer=regularizers.l2(1e-6))(inputs)\n",
    "\n",
    "    b1 = layers.Conv1D(96, 3, padding=\"same\", activation=\"relu\",\n",
    "                       kernel_regularizer=regularizers.l2(1e-6))(x)\n",
    "    b2 = layers.Conv1D(96, 5, padding=\"same\", activation=\"relu\",\n",
    "                       kernel_regularizer=regularizers.l2(1e-6))(x)\n",
    "    b3 = layers.Conv1D(96, 7, padding=\"same\", activation=\"relu\",\n",
    "                       kernel_regularizer=regularizers.l2(1e-6))(x)\n",
    "    x = layers.Concatenate()([b1, b2, b3])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.SpatialDropout1D(0.25)(x)\n",
    "\n",
    "    x = layers.Bidirectional(layers.LSTM(80, return_sequences=True,\n",
    "                                         dropout=0.2,\n",
    "                                         kernel_regularizer=regularizers.l2(1e-6)))(x)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "    x = layers.Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(1e-6))(x)\n",
    "    x = layers.Dropout(DROPOUT)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "model = build_model(vocab_size=len(vocab), num_classes=num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597d2b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 3s/step - accuracy: 0.7593 - loss: 0.6229 - val_accuracy: 0.2032 - val_loss: 1.3940 - learning_rate: 0.0010\n",
      "Epoch 2/12\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 3s/step - accuracy: 0.9351 - loss: 0.1862 - val_accuracy: 0.2404 - val_loss: 1.3865 - learning_rate: 0.0010\n",
      "Epoch 3/12\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 3s/step - accuracy: 0.9540 - loss: 0.1357 - val_accuracy: 0.6021 - val_loss: 1.0793 - learning_rate: 0.0010\n",
      "Epoch 4/12\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 4s/step - accuracy: 0.9577 - loss: 0.1234 - val_accuracy: 0.5767 - val_loss: 0.7807 - learning_rate: 0.0010\n",
      "Epoch 5/12\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9623 - loss: 0.1137\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 3s/step - accuracy: 0.9612 - loss: 0.1142 - val_accuracy: 0.5865 - val_loss: 1.2563 - learning_rate: 0.0010\n",
      "Epoch 6/12\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9633 - loss: 0.1064\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 4s/step - accuracy: 0.9637 - loss: 0.1054 - val_accuracy: 0.6037 - val_loss: 1.9322 - learning_rate: 5.0000e-04\n",
      "Epoch 7/12\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9655 - loss: 0.1024\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 4s/step - accuracy: 0.9648 - loss: 0.1013 - val_accuracy: 0.6102 - val_loss: 2.2531 - learning_rate: 2.5000e-04\n",
      "\n",
      "[Line-level] Accuracy: 0.9349  Macro-F1: 0.9031\n",
      "\n",
      "[Line-level] Classification Report\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "            Disk full       1.00      0.95      0.97      2508\n",
      "         Machine down       0.96      0.93      0.94      6415\n",
      "Network disconnection       1.00      0.98      0.99      4001\n",
      "               Normal       0.63      0.83      0.71      1284\n",
      "\n",
      "             accuracy                           0.93     14208\n",
      "            macro avg       0.89      0.92      0.90     14208\n",
      "         weighted avg       0.95      0.93      0.94     14208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "opt = optimizers.Adam(learning_rate=BASE_LR)\n",
    "model.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "cb = [\n",
    "    callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n",
    "    callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=1, min_lr=1e-5, verbose=1),\n",
    "    callbacks.ModelCheckpoint(Path(conf.EXTRACTED_DATA_PATH) / \"line_charcnn_lstm.keras\", save_best_only=True, monitor=\"val_loss\")\n",
    "]\n",
    "\n",
    "# Training\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=cb,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluation: line-level\n",
    "y_pred_prob = model.predict(test_ds, verbose=0)\n",
    "y_pred = y_pred_prob.argmax(axis=1)\n",
    "\n",
    "print(\"\\n[Line-level] Accuracy: %.4f  Macro-F1: %.4f\" %(accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average=\"macro\")))\n",
    "print(\"\\n[Line-level] Classification Report\\n\",classification_report(y_test, y_pred, target_names=list(le.classes_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ce29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[App-level from mean prob] Accuracy: 1.0000  Macro-F1: 1.0000\n",
      "\n",
      "[App-level] Classification Report\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "            Disk full       1.00      1.00      1.00         2\n",
      "         Machine down       1.00      1.00      1.00         5\n",
      "Network disconnection       1.00      1.00      1.00         1\n",
      "               Normal       1.00      1.00      1.00         1\n",
      "\n",
      "             accuracy                           1.00         9\n",
      "            macro avg       1.00      1.00      1.00         9\n",
      "         weighted avg       1.00      1.00      1.00         9\n",
      "\n",
      "\n",
      "[App-level] Confusion Matrix\n",
      "                             pred_Disk full  pred_Machine down  \\\n",
      "true_Disk full                           2                  0   \n",
      "true_Machine down                        0                  5   \n",
      "true_Network disconnection               0                  0   \n",
      "true_Normal                              0                  0   \n",
      "\n",
      "                            pred_Network disconnection  pred_Normal  \n",
      "true_Disk full                                       0            0  \n",
      "true_Machine down                                    0            0  \n",
      "true_Network disconnection                           1            0  \n",
      "true_Normal                                          0            1  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "idx_to_app = [None] * len(X_test_lines)\n",
    "for app, indices in appidx_test.items():\n",
    "    for idx in indices:\n",
    "        if 0 <= idx < len(idx_to_app):\n",
    "            idx_to_app[idx] = app\n",
    "\n",
    "app_true = {}\n",
    "app_probs = defaultdict(list)\n",
    "\n",
    "for i, app in enumerate(idx_to_app):\n",
    "    if app is None:\n",
    "        continue\n",
    "    app_true.setdefault(app, y_test[i])\n",
    "    # keep only reasonably confident lines (tune CONF_FLOOR 0.4–0.6)\n",
    "    if float(np.max(y_pred_prob[i])) >= CONF_FLOOR:\n",
    "        app_probs[app].append(y_pred_prob[i])\n",
    "\n",
    "app_level_true, app_level_pred = [], []\n",
    "for app in app_true.keys():\n",
    "    probs = app_probs.get(app, None)\n",
    "    if not probs:  # if all lines filtered, fallback to all lines for that app\n",
    "        probs = [y_pred_prob[i] for i, a in enumerate(idx_to_app) if a == app]\n",
    "    mean_prob = np.mean(probs, axis=0)\n",
    "    app_level_pred.append(int(np.argmax(mean_prob)))\n",
    "    app_level_true.append(int(app_true[app]))\n",
    "\n",
    "print(\"\\n[App-level from mean prob] Accuracy: %.4f  Macro-F1: %.4f\" %\n",
    "      (accuracy_score(app_level_true, app_level_pred),\n",
    "       f1_score(app_level_true, app_level_pred, average=\"macro\")))\n",
    "print(\"\\n[App-level] Classification Report\\n\",classification_report(app_level_true, app_level_pred, target_names=list(le.classes_)))\n",
    "print(\"\\n[App-level] Confusion Matrix\\n\",\n",
    "                pd.DataFrame(confusion_matrix(app_level_true, app_level_pred),\n",
    "                   index=[f\"true_{c}\" for c in le.classes_],\n",
    "                   columns=[f\"pred_{c}\" for c in le.classes_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9510ee8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\processed\\\\label_encoder_line.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model.save(Path(conf.PROCESSED_DATA_PATH) / \"line_charcnn_lstm_final.keras\")\n",
    "\n",
    "vec_config = vec.get_config()\n",
    "vec_weights = vec.get_weights()\n",
    "vec_vocabulary = vec.get_vocabulary()\n",
    "joblib.dump({\"config\": vec_config, \"weights\": vec_weights,\"vocabulary\":vec_vocabulary}, Path(conf.PROCESSED_DATA_PATH) / \"textvectorization_char.pkl\")\n",
    "\n",
    "\n",
    "joblib.dump(le, Path(conf.PROCESSED_DATA_PATH) / \"label_encoder_line.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f3b18ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Disk full' 'Machine down' 'Network disconnection' 'Normal']\n"
     ]
    }
   ],
   "source": [
    "print(le.classes_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
